
# 最优化

* [过拟合与欠拟合](https://blog.zhujian.life/posts/2f1a2a1c.html)
* 预处理
    * [特征缩放](https://blog.zhujian.life/posts/dea583b1.html)
    * [合理性检查](https://blog.zhujian.life/posts/869619ac.html)
    * [权重初始化](https://blog.zhujian.life/posts/cfd35552.html)
* 反向传播
    * [成绩函数、目标函数、代价函数和损失函数](https://blog.zhujian.life/posts/5d2f01d1.html)
    * [小批量随机梯度下降](https://blog.zhujian.life/posts/3c50d4b7.html)
    * [动量更新](https://blog.zhujian.life/posts/2b34c959.html)
    * [Nesterov加速梯度](https://blog.zhujian.life/posts/e51acd5.html)
    * [AdaGrad、RMSProp和Adam](https://blog.zhujian.life/posts/2bdd8f16.html)
    * [梯度检查](https://blog.zhujian.life/posts/d91a1c6f.html)
    * [超参数优化](https://blog.zhujian.life/posts/a042eba2.html)
* [正则化](https://blog.zhujian.life/posts/ce0afb50.html)
    * 学习率调度
        * [学习率退火](https://blog.zhujian.life/posts/936eda30.html)
        * [[LR Scheduler]余弦退火](https://blog.zhujian.life/posts/6eb7f24f.html)
        * [[LR Scheduler]warmup](https://blog.zhujian.life/posts/f311f0.html)
        * [[LR Scheduler]如何找到最优学习率](https://blog.zhujian.life/posts/78a36c78.html)
        * [如何找到最优权重衰减值](https://blog.zhujian.life/posts/b2e2c47b.html)
    * [随机失活](https://blog.zhujian.life/posts/20cc7a49.html)
        * [随机失活-pytorch](https://blog.zhujian.life/posts/2bee4fce.html)
* [模型集成](https://blog.zhujian.life/posts/e0761e53.html)
* [Hard Negative Mining](https://blog.zhujian.life/posts/bc29003.html)
* [[目标检测]Non-Maximum Suppression](https://blog.zhujian.life/posts/7b326d08.html)
* 损失函数
    * [标签平滑正则化](https://blog.zhujian.life/posts/9a85fe27.html)
* 迁移学习
    * [[译]TorchVision Object Detection Finetuning Tutorial](https://blog.zhujian.life/posts/1a1c504e.html)
    * [[译]Transfer Learning for Computer Vision Tutorial](https://blog.zhujian.life/posts/c8566254.html)
    * [迁移学习](https://blog.zhujian.life/posts/c7511b44.html)